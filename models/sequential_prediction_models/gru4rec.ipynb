{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "users, movies, timestamp = [], [], []\n",
    "user_len, movie_len = 0, 0\n",
    "movie_hist_dict = defaultdict(list)\n",
    "\n",
    "with open(\"../../data/ratings.dat\", \"r\") as f:\n",
    "    for line in f:\n",
    "        u, m, r, t = line.split(\"::\")\n",
    "        user_len = max(user_len, int(u))\n",
    "        movie_len = max(movie_len, int(m))\n",
    "        movie_hist_dict[u].append([m,t])\n",
    "\n",
    "\n",
    "for u in movie_hist_dict:\n",
    "    movie_hist_dict[u].sort(key=lambda x: int(x[1]))\n",
    "    movie_hist_dict[u] = [int(movie) for movie, _ in movie_hist_dict[u]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "\n",
    "def build_session_parallel_batches(movie_hist_dict, batch_size, max_steps=20):\n",
    "    sessions = list(movie_hist_dict.values())\n",
    "    session_queue = deque(sessions)  # ì „ì²´ ì„¸ì…˜ì„ íë¡œ ê´€ë¦¬\n",
    "\n",
    "    active_sessions = []\n",
    "    session_positions = []\n",
    "\n",
    "    # ì´ˆê¸° active session ì±„ìš°ê¸°\n",
    "    for _ in range(batch_size):\n",
    "        if session_queue:\n",
    "            s = session_queue.popleft()\n",
    "            active_sessions.append(s)\n",
    "            session_positions.append(0)\n",
    "\n",
    "    batch_inputs = []\n",
    "    batch_targets = []\n",
    "    reset_masks = []\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        input_batch = []\n",
    "        target_batch = []\n",
    "        reset_batch = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            session = active_sessions[i]\n",
    "            pos = session_positions[i]\n",
    "\n",
    "            if pos + 1 < len(session):\n",
    "                input_batch.append(session[pos])\n",
    "                target_batch.append(session[pos + 1])\n",
    "                reset_batch.append(0 if pos > 0 else 1)\n",
    "                session_positions[i] += 1\n",
    "            else:\n",
    "                # ì„¸ì…˜ì´ ëë‚¬ìœ¼ë©´ ìƒˆë¡œìš´ ì„¸ì…˜ìœ¼ë¡œ êµì²´\n",
    "                if session_queue:\n",
    "                    new_session = session_queue.popleft()\n",
    "                    active_sessions[i] = new_session\n",
    "                    session_positions[i] = 0\n",
    "\n",
    "                    input_batch.append(new_session[0])\n",
    "                    if len(new_session) > 1:\n",
    "                        target_batch.append(new_session[1])\n",
    "                    else:\n",
    "                        target_batch.append(-1)  # ë‹¨ì¼ ì•„ì´í…œ ì„¸ì…˜\n",
    "                    reset_batch.append(1)\n",
    "                    session_positions[i] += 1\n",
    "                else:\n",
    "                    # ë” ì´ìƒ ì„¸ì…˜ì´ ì—†ë‹¤ë©´ padding\n",
    "                    input_batch.append(0)\n",
    "                    target_batch.append(-1)\n",
    "                    reset_batch.append(1)\n",
    "\n",
    "        batch_inputs.append(input_batch)\n",
    "        batch_targets.append(target_batch)\n",
    "        reset_masks.append(reset_batch)\n",
    "\n",
    "    return (\n",
    "        torch.tensor(batch_inputs),      # (timesteps, batch_size)\n",
    "        torch.tensor(batch_targets),\n",
    "        torch.tensor(reset_masks)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ¢ Inputs:\n",
      " tensor([[3186, 1198,  593,  ..., 2243,  748, 2643],\n",
      "        [1270, 1210, 2858,  ..., 1968, 1198,  266],\n",
      "        [1721, 1217, 3534,  ..., 2976, 3421, 1269],\n",
      "        ...,\n",
      "        [ 317, 2092,  150,  ...,  199, 3061, 1100],\n",
      "        [2872, 2371,  162,  ..., 2971, 2941, 3667],\n",
      "        [ 653,  587,  457,  ..., 1035, 1288, 1431]])\n",
      "ğŸ¯ Targets:\n",
      " tensor([[1270, 1210, 2858,  ..., 1968, 1198,  266],\n",
      "        [1721, 1217, 3534,  ..., 2976, 3421, 1269],\n",
      "        [1022, 2717, 1968,  ..., 3033, 1968, 2555],\n",
      "        ...,\n",
      "        [2872, 2083,  162,  ..., 2971, 2941, 3667],\n",
      "        [ 653,  587,  457,  ..., 1035, 1288, 1431],\n",
      "        [   2, 3004, 2336,  ..., 1081,  900, 1544]])\n",
      "ğŸ”„ Reset Masks:\n",
      " tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 1, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "max_steps = max(len(session) for session in movie_hist_dict.values()) - 1\n",
    "\n",
    "batch_inputs, batch_targets, reset_masks = build_session_parallel_batches(movie_hist_dict, batch_size=16, max_steps=max_steps)\n",
    "\n",
    "print(\"ğŸŸ¢ Inputs:\\n\", batch_inputs)\n",
    "print(\"ğŸ¯ Targets:\\n\", batch_targets)\n",
    "print(\"ğŸ”„ Reset Masks:\\n\", reset_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Gru4Rec(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, device=\"cpu\"):\n",
    "        super(Gru4Rec, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size).to(device)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers, batch_first=True).to(device)\n",
    "        self.linear = nn.Linear(hidden_size, output_size).to(device)\n",
    "\n",
    "    def forward(self, input_seq, hidden=None, reset_mask=None):\n",
    "        input_seq = input_seq.to(self.device) \n",
    "        input_seq = input_seq.unsqueeze(1)\n",
    "\n",
    "        batch_size = input_seq.size(0)\n",
    "\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n",
    "\n",
    "        if reset_mask is not None:\n",
    "            reset_mask = reset_mask.to(self.device).float().view(1, batch_size, 1)\n",
    "            zero_hidden = torch.zeros_like(hidden)\n",
    "            hidden = hidden * (1.0 - reset_mask) + zero_hidden * reset_mask\n",
    "\n",
    "        embedded = self.embedding(input_seq)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        predictions = self.linear(output[:, -1, :])\n",
    "        return predictions, hidden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(predictions, targets, k=10):\n",
    "\n",
    "    _, top_k_idx = torch.topk(predictions, k, dim=-1, largest=True, sorted=True)\n",
    "\n",
    "    recall = 0\n",
    "    for idx in range(predictions.size(0)):\n",
    "        if targets[idx].item() in top_k_idx[idx]:\n",
    "            recall += 1\n",
    "    return recall / predictions.size(0)\n",
    "\n",
    "# MRR@k ê³„ì‚° í•¨ìˆ˜\n",
    "def mrr_at_k(predictions, targets, k=20):\n",
    "    _, top_k_idx = torch.topk(predictions, k, dim=-1, largest=True, sorted=True)\n",
    "    mrr = 0\n",
    "    for idx in range(predictions.size(0)):  \n",
    "        rank = (top_k_idx[idx] == targets[idx].item()).nonzero()\n",
    "        if rank.size(0) > 0:\n",
    "            mrr += 1 / (rank.item() + 1) \n",
    "    return mrr / predictions.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = movie_len + 1  \n",
    "hidden_size = 128\n",
    "output_size = input_size\n",
    "num_layers = 2\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 60\n",
    "device = device\n",
    "r_k = 10\n",
    "m_k = 20\n",
    "max_steps= max_steps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = Gru4Rec(input_size, hidden_size, output_size, num_layers,device=device).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete. Average Loss: 7.768088232527757, Recall@10: 0.022616731517509727, MRR@20: 0.007958387272345525\n",
      "Epoch 11 complete. Average Loss: 6.58779737457691, Recall@10: 0.12848573281452658, MRR@20: 0.0629947032106301\n",
      "Epoch 21 complete. Average Loss: 5.714881359319691, Recall@10: 0.2689688715953307, MRR@20: 0.13213215154977456\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0  # ì—í­ë‹¹ í‰ê·  ì†ì‹¤ê°’ ê³„ì‚°ì„ ìœ„í•œ ë³€ìˆ˜\n",
    "    epoch_recall = 0.0  # Recall í‰ê·  ê³„ì‚° ë³€ìˆ˜\n",
    "    epoch_mrr = 0.0     # MRR í‰ê·  ê³„ì‚° ë³€ìˆ˜\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        input_seq = batch_inputs[step].to(device)         # (batch_size,)\n",
    "        target_seq = batch_targets[step].to(device)       # (batch_size,)\n",
    "        reset_mask = reset_masks[step].to(device)   # (batch_size,)\n",
    "\n",
    "        predictions,_ = model(input_seq,reset_mask=reset_mask)\n",
    "\n",
    "        loss = criterion(predictions, target_seq)\n",
    "\n",
    "        epoch_loss += loss.item() \n",
    "\n",
    "        recall = recall_at_k(predictions, target_seq, r_k)\n",
    "        epoch_recall += recall\n",
    "        \n",
    "\n",
    "        mrr = mrr_at_k(predictions, target_seq, m_k)\n",
    "        epoch_mrr += mrr\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        predictions = torch.argmax(predictions, dim=-1)  # (batch_size,)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    # í•œ ì—í­ì´ ëë‚  ë•Œë§ˆë‹¤ í‰ê·  ì†ì‹¤ê³¼ Recall@20, MRR@20 ì¶œë ¥\n",
    "    if(epoch%10==0):\n",
    "      print(f\"Epoch {epoch+1} complete. Average Loss: {epoch_loss / max_steps}, \"\n",
    "        f\"Recall@10: {epoch_recall / max_steps}, MRR@20: {epoch_mrr / max_steps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_movie(model, user_history, top_k=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden = None\n",
    "        reset_mask = torch.tensor([1], dtype=torch.float32)  # ì²« ì…ë ¥ì€ ë¦¬ì…‹ í•„ìš”\n",
    "\n",
    "        for i, movie_id in enumerate(user_history):\n",
    "            input_seq = torch.tensor([movie_id])  # (batch=1)\n",
    "            reset = reset_mask if i == 0 else torch.tensor([0], dtype=torch.float32)\n",
    "            output, hidden = model(input_seq, hidden=hidden, reset_mask=reset)\n",
    "\n",
    "        # ë§ˆì§€ë§‰ outputìœ¼ë¡œë¶€í„° top-k ì˜í™” ì˜ˆì¸¡\n",
    "        topk_values, topk_indices = torch.topk(output, top_k)\n",
    "        return topk_indices.squeeze().tolist()  # ì˜ˆì¸¡ëœ top-k ì˜í™” ID ë¦¬ìŠ¤íŠ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 ì¶”ì²œ ì˜í™” ID: [720, 318, 2396, 3753, 2858]\n"
     ]
    }
   ],
   "source": [
    "user_history = [1, 5, 100, 4, 20, 50, 30]\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "recommended_movies = predict_next_movie(model, user_history, top_k=5)\n",
    "\n",
    "print(\"Top-5 ì¶”ì²œ ì˜í™” ID:\", recommended_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
